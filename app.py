import io
import os
import json
from typing import List, Optional, Tuple

import streamlit as st
import requests
import fitz  # PyMuPDF
from PIL import Image
import pytesseract

from docx import Document
from docx.shared import Pt, Inches
from docx.oxml.ns import qn

from streamlit_paste_button import paste_image_button as paste_btn


# ======================================================
# SambaNova (OpenAI-compatible)
# ======================================================
SAMBANOVA_BASE_URL = "https://api.sambanova.ai/v1"
DEFAULT_MODEL = "Meta-Llama-3.3-70B-Instruct"


def sambanova_chat(api_key: str, model: str, messages: List[dict], timeout: int = 90) -> str:
    if not api_key:
        raise RuntimeError("Ch∆∞a nh·∫≠p SambaNova API Key.")
    url = f"{SAMBANOVA_BASE_URL}/chat/completions"
    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
    payload = {"model": model, "messages": messages, "temperature": 0.1, "max_tokens": 2048}
    r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=timeout)
    if r.status_code != 200:
        raise RuntimeError(f"SambaNova API l·ªói {r.status_code}: {r.text}")
    return r.json()["choices"][0]["message"]["content"]


SYSTEM_RULES = """
B·∫°n l√† c√¥ng c·ª• chu·∫©n ho√° vƒÉn b·∫£n ƒë·ªÉ ƒë∆∞a v√†o Word.

Y√äU C·∫¶U NGHI√äM NG·∫∂T:
1) GI·ªÆ NGUY√äN N·ªòI DUNG: kh√¥ng th√™m/b·ªõt/suy di·ªÖn.
2) GI·ªÆ NGUY√äN XU·ªêNG D√íNG: kh√¥ng t·ª± g·ªôp d√≤ng, kh√¥ng t·ª± ng·∫Øt d√≤ng l·∫°i.
3) M·ªåI BI·ªÇU TH·ª®C/CT TO√ÅN PH·∫¢I N·∫∞M TRONG $...$.
   - N·∫øu ƒë√£ l√† LaTeX th√¨ v·∫´n ph·∫£i b·ªçc $...$ (n·∫øu ch∆∞a b·ªçc).
   - Kh√¥ng d√πng \\( \\) ho·∫∑c \\[ \\] ho·∫∑c $$ $$.
4) VƒÉn b·∫£n th∆∞·ªùng KH√îNG ƒë·∫∑t trong $...$.
5) Ch·ªâ tr·∫£ v·ªÅ TEXT THU·∫¶N, kh√¥ng markdown, kh√¥ng th√™m ti√™u ƒë·ªÅ.
""".strip()


def normalize_with_ai(api_key: str, model: str, raw_text: str) -> str:
    messages = [{"role": "system", "content": SYSTEM_RULES}, {"role": "user", "content": raw_text}]
    return sambanova_chat(api_key, model, messages).strip()


# ======================================================
# OCR (fail-soft, kh√¥ng l√†m app ch·∫øt)
# ======================================================
def ocr_image_pil(img: Image.Image) -> str:
    try:
        return pytesseract.image_to_string(img) or ""
    except Exception as e:
        st.warning(
            "‚ö†Ô∏è OCR kh√¥ng ch·∫°y ƒë∆∞·ª£c (thi·∫øu Tesseract tr√™n m√¥i tr∆∞·ªùng deploy). "
            "B·ªè qua OCR ƒë·ªÉ app kh√¥ng b·ªã l·ªói.\n"
            f"Chi ti·∫øt: {e}"
        )
        return ""


# ======================================================
# PDF: "phi√™n b·∫£n ƒë·∫ßu ti√™n" = ∆∞u ti√™n TEXT LAYER
# - Kh√¥ng render trang th√†nh ·∫£nh tr·ª´ khi user ch·ªçn ƒë√≠nh k√®m trang scan
# ======================================================
def render_page_image(page: fitz.Page, dpi: int = 200) -> Image.Image:
    zoom = dpi / 72
    pix = page.get_pixmap(matrix=fitz.Matrix(zoom, zoom), alpha=False)
    return Image.open(io.BytesIO(pix.tobytes("png"))).convert("RGB")


def extract_pdf_text_first(
    pdf_bytes: bytes,
    scan_handling: str = "note",   # "note" | "embed" | "ocr"
    dpi: int = 200,
) -> Tuple[str, List[Image.Image]]:
    """
    Tr·∫£ v·ªÅ (text_all, scan_images_to_embed)

    scan_handling:
      - "note": kh√¥ng OCR, kh√¥ng nh√©t ·∫£nh; ch·ªâ ghi ch√∫ trang scan.
      - "embed": kh√¥ng OCR; ch·ªâ ƒë√≠nh k√®m ·∫£nh trang scan v√†o Word.
      - "ocr": OCR trang scan (n·∫øu c√≥ Tesseract), n·∫øu kh√¥ng th√¨ note.
    """
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    out_lines: List[str] = []
    scan_images: List[Image.Image] = []

    for i in range(len(doc)):
        page = doc.load_page(i)
        page_no = i + 1

        txt = (page.get_text("text") or "").replace("\r\n", "\n").replace("\r", "\n").strip()

        if txt:
            # Gi·ªëng b·∫£n ƒë·∫ßu: c√≥ text layer th√¨ l·∫•y th·∫≥ng
            out_lines.append(f"--- Trang {page_no} ---")
            out_lines.append(txt)
        else:
            # Trang scan/·∫£nh
            out_lines.append(f"--- Trang {page_no} ---")
            if scan_handling == "embed":
                img = render_page_image(page, dpi=dpi)
                scan_images.append(img)
                out_lines.append("(Trang d·∫°ng ·∫£nh/scan: kh√¥ng c√≥ text layer. ƒê√≠nh k√®m ·∫£nh trang ·ªü d∆∞·ªõi.)")
            elif scan_handling == "ocr":
                img = render_page_image(page, dpi=dpi)
                ocr_txt = ocr_image_pil(img).strip()
                if ocr_txt:
                    out_lines.append(ocr_txt)
                else:
                    out_lines.append("(Trang d·∫°ng ·∫£nh/scan: OCR kh√¥ng ch·∫°y ho·∫∑c kh√¥ng ƒë·ªçc ƒë∆∞·ª£c.)")
            else:
                out_lines.append("(Trang d·∫°ng ·∫£nh/scan: kh√¥ng c√≥ text layer. B·∫≠t OCR ho·∫∑c ƒê√≠nh k√®m ·∫£nh trang n·∫øu c·∫ßn.)")

        out_lines.append("")  # d√≤ng tr·ªëng gi·ªØa c√°c trang

    doc.close()
    return "\n".join(out_lines).strip(), scan_images


# ======================================================
# Word export
# ======================================================
def set_doc_default_font(doc: Document, font_name: str = "Times New Roman", font_size_pt: int = 13):
    style = doc.styles["Normal"]
    font = style.font
    font.name = font_name
    font.size = Pt(font_size_pt)
    style._element.rPr.rFonts.set(qn("w:eastAsia"), font_name)


def add_text_preserve_lines(doc: Document, text: str):
    text = (text or "").replace("\r\n", "\n").replace("\r", "\n")
    for line in text.split("\n"):
        doc.add_paragraph(line)


def build_docx(
    title: str,
    final_text: str,
    scan_images: List[Image.Image],
    embed_scan_images: bool,
) -> bytes:
    doc = Document()
    set_doc_default_font(doc, "Times New Roman", 13)

    if title.strip():
        doc.add_heading(title.strip(), level=1)

    # Text tr∆∞·ªõc (gi·ªëng b·∫£n ƒë·∫ßu)
    add_text_preserve_lines(doc, final_text)

    # Ch·ªâ k√®m ·∫£nh n·∫øu user ch·ªçn ch·∫ø ƒë·ªô embed scan
    if embed_scan_images and scan_images:
        doc.add_page_break()
        doc.add_paragraph("·∫¢nh c√°c trang scan/kh√¥ng c√≥ text layer:")
        for im in scan_images:
            buf = io.BytesIO()
            im.save(buf, format="PNG")
            buf.seek(0)
            doc.add_picture(buf, width=Inches(6.5))

    out = io.BytesIO()
    doc.save(out)
    return out.getvalue()


# ======================================================
# Streamlit UI
# ======================================================
st.set_page_config(page_title="PDF/·∫¢nh ‚Üí Word (b·∫£n ƒë·∫ßu ti√™n)", layout="wide")
st.title("üìÑ PDF/·∫¢nh ‚Üí Word (.docx) ‚Äî b·∫£n gi·ªëng phi√™n b·∫£n ƒë·∫ßu ti√™n (text-first)")

with st.sidebar:
    st.header("‚öôÔ∏è C·∫•u h√¨nh")
    api_key = st.text_input("SambaNova API Key", type="password", value=os.getenv("SAMBANOVA_API_KEY", ""))
    model = st.text_input("Model", value=DEFAULT_MODEL)

    use_ai = st.checkbox("D√πng AI √©p c√¥ng th·ª©c v√†o $...$", value=True)

    st.subheader("PDF scan/·∫£nh x·ª≠ l√Ω th·∫ø n√†o?")
    scan_mode = st.radio(
        "Ch·ªçn 1",
        options=[
            ("note", "Ch·ªâ ghi ch√∫ (kh√¥ng OCR, kh√¥ng ·∫£nh) ‚Äî gi·ªëng b·∫£n ƒë·∫ßu nh·∫•t"),
            ("embed", "ƒê√≠nh k√®m ·∫£nh trang scan (kh√¥ng OCR)"),
            ("ocr", "OCR trang scan (c·∫ßn Tesseract; n·∫øu thi·∫øu s·∫Ω t·ª± b·ªè qua)"),
        ],
        index=0,
        format_func=lambda x: x[1],
    )[0]

    dpi = st.slider("DPI render (ch·ªâ d√πng khi scan_mode=embed/ocr)", 120, 300, 200, 10)

    st.caption("M·∫∑c ƒë·ªãnh: KH√îNG nh√©t ·∫£nh v√†o Word, ch·ªâ l·∫•y TEXT layer nh∆∞ b·∫£n ƒë·∫ßu.")

col1, col2 = st.columns([1, 1], gap="large")

with col1:
    st.subheader("1) Upload PDF / d√°n ·∫£nh")

    # Paste ·∫£nh (tu·ª≥ ch·ªçn)
    st.markdown("**D√°n ·∫£nh (Ctrl+V)**: b·∫•m n√∫t r·ªìi Ctrl+V (tu·ª≥ m√°y).")
    paste = paste_btn("üìã Paste ·∫£nh (Ctrl+V)")
    pasted_img: Optional[Image.Image] = None
    if paste.image_data is not None:
        pasted_img = paste.image_data
        st.image(pasted_img, caption="·∫¢nh d√°n", use_container_width=True)

    st.markdown("**Upload PDF** (∆∞u ti√™n lo·∫°i c√≥ text layer):")
    pdf_file = st.file_uploader("Ch·ªçn file PDF", type=["pdf"])

with col2:
    st.subheader("2) Chuy·ªÉn ƒë·ªïi & t·∫£i Word")
    title = st.text_input("Ti√™u ƒë·ªÅ (tu·ª≥ ch·ªçn)", value="")

    if st.button("üöÄ Chuy·ªÉn PDF ‚Üí Word", type="primary"):
        if not pdf_file:
            st.error("Ch∆∞a ch·ªçn PDF.")
            st.stop()

        pdf_bytes = pdf_file.read()

        with st.spinner("ƒêang tr√≠ch xu·∫•t TEXT layer t·ª´ PDF (gi·ªëng b·∫£n ƒë·∫ßu) ..."):
            raw_text, scan_images = extract_pdf_text_first(pdf_bytes, scan_handling=scan_mode, dpi=dpi)

        final_text = raw_text
        if use_ai and raw_text.strip():
            if not api_key.strip():
                st.warning("Ch∆∞a nh·∫≠p API key n√™n b·ªè qua AI, xu·∫•t text th√¥.")
            else:
                with st.spinner("ƒêang chu·∫©n ho√° $...$ b·∫±ng SambaNova ..."):
                    final_text = normalize_with_ai(api_key, model, raw_text)

        st.markdown("### Xem tr∆∞·ªõc (text)")
        st.text_area("Preview", final_text, height=360)

        docx_bytes = build_docx(
            title=title,
            final_text=final_text,
            scan_images=scan_images,
            embed_scan_images=(scan_mode == "embed"),
        )

        st.success("Xong! T·∫£i file Word:")
        st.download_button(
            "‚¨áÔ∏è Download .docx",
            data=docx_bytes,
            file_name="pdf_to_word.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        )

    st.divider()
    st.caption("N·∫øu PDF l√† scan (kh√¥ng c√≥ text layer) th√¨ b·∫£n 'gi·ªëng b·∫£n ƒë·∫ßu' s·∫Ω kh√¥ng th·ªÉ ra ch·ªØ n·∫øu kh√¥ng OCR.")
