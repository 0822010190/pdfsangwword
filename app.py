import io
import os
import re
import json
import base64
from dataclasses import dataclass
from typing import List, Optional, Tuple

import streamlit as st
import requests
from PIL import Image

import fitz  # PyMuPDF
import pytesseract

from docx import Document
from docx.shared import Inches

from streamlit_paste_button import paste_image_button as paste_btn


# =========================
# SambaNova (OpenAI-compatible) client via requests
# Base URL: https://api.sambanova.ai/v1  (docs)
# Chat completions endpoint: /chat/completions
# =========================
SAMBANOVA_BASE_URL = "https://api.sambanova.ai/v1"


class SambaNovaError(RuntimeError):
    pass


def sambanova_chat(
    api_key: str,
    model: str,
    messages: List[dict],
    temperature: float = 0.2,
    max_tokens: int = 2048,
    timeout: int = 90,
) -> str:
    if not api_key:
        raise SambaNovaError("Thi·∫øu SAMBANOVA_API_KEY.")
    url = f"{SAMBANOVA_BASE_URL}/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": model,
        "messages": messages,
        "temperature": temperature,
        "max_tokens": max_tokens,
    }

    r = requests.post(url, headers=headers, data=json.dumps(payload), timeout=timeout)
    if r.status_code != 200:
        raise SambaNovaError(f"SambaNova API l·ªói {r.status_code}: {r.text}")

    data = r.json()
    try:
        return data["choices"][0]["message"]["content"]
    except Exception:
        raise SambaNovaError(f"Ph·∫£n h·ªìi kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng: {data}")


# =========================
# OCR + PDF extraction
# =========================
def pil_from_bytes(b: bytes) -> Image.Image:
    return Image.open(io.BytesIO(b)).convert("RGB")


def ocr_image_pil(img: Image.Image) -> str:
    """
    OCR ·∫£nh b·∫±ng Tesseract.
    N·∫øu m√°y ch∆∞a c√†i Tesseract, h√†m s·∫Ω b√°o l·ªói r√µ.
    """
    try:
        text = pytesseract.image_to_string(img)  # m·∫∑c ƒë·ªãnh eng
        return text or ""
    except Exception as e:
        raise RuntimeError(
            "Kh√¥ng OCR ƒë∆∞·ª£c. M√°y ch∆∞a c√†i Tesseract OCR ho·∫∑c ch∆∞a c·∫•u h√¨nh PATH. "
            f"Chi ti·∫øt: {e}"
        )


def extract_pdf_text_or_ocr(pdf_bytes: bytes, dpi: int = 200) -> Tuple[str, List[Image.Image]]:
    """
    Tr·∫£ v·ªÅ (raw_text, rendered_page_images).
    - N·∫øu PDF c√≥ text layer: l·∫•y text tr·ª±c ti·∫øp.
    - N·∫øu √≠t text: render trang -> OCR.
    """
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    page_images: List[Image.Image] = []
    texts: List[str] = []

    for i in range(len(doc)):
        page = doc.load_page(i)
        txt = page.get_text("text") or ""
        txt_clean = txt.strip()

        # Render ·∫£nh trang ƒë·ªÉ (1) ƒë√≠nh k√®m Word n·∫øu mu·ªën, (2) OCR khi c·∫ßn
        zoom = dpi / 72
        mat = fitz.Matrix(zoom, zoom)
        pix = page.get_pixmap(matrix=mat, alpha=False)
        img = Image.open(io.BytesIO(pix.tobytes("png"))).convert("RGB")
        page_images.append(img)

        # Heuristic: n·∫øu c√≥ ƒë·ªß text th√¨ d√πng lu√¥n, n·∫øu qu√° √≠t th√¨ OCR
        if len(txt_clean) >= 50:
            texts.append(txt)
        else:
            ocr_txt = ocr_image_pil(img)
            texts.append(ocr_txt)

    doc.close()
    raw = "\n\n".join([t.strip("\n") for t in texts if t is not None])
    return raw, page_images


# =========================
# Strict formatting prompt: keep line breaks, enforce $...$ for math
# =========================
SYSTEM_RULES = r"""
B·∫°n l√† c√¥ng c·ª• chuy·ªÉn ƒë·ªïi n·ªôi dung t·ª´ OCR/PDF sang vƒÉn b·∫£n ƒë·ªÉ ƒë∆∞a v√†o Word.
Y√äU C·∫¶U NGHI√äM NG·∫∂T:

1) GI·ªÆ NGUY√äN N·ªòI DUNG: kh√¥ng ƒë∆∞·ª£c t·ª± √Ω th√™m, b·ªõt, suy di·ªÖn.
2) GI·ªÆ NGUY√äN XU·ªêNG D√íNG: b·∫£o to√†n c·∫•u tr√∫c ƒëo·∫°n/ d√≤ng nh∆∞ d·ªØ li·ªáu v√†o. Kh√¥ng t·ª± g·ªôp d√≤ng.
3) C√îNG TH·ª®C TO√ÅN PH·∫¢I N·∫∞M TRONG D·∫§U $...$:
   - B·∫•t k·ª≥ bi·ªÉu th·ª©c to√°n n√†o (ph√¢n s·ªë, cƒÉn, m≈©, ch·ªâ s·ªë, k√Ω hi·ªáu ‚à†, ‚üÇ, ‚à•, ‚àà, ‚â§, ‚â•, œÄ, ‚Ä¶, ph∆∞∆°ng tr√¨nh, b·∫•t ƒë·∫≥ng th·ª©c, bi·ªÉu th·ª©c ƒë·∫°i s·ªë, h√¨nh h·ªçc) ƒë·ªÅu ph·∫£i ƒë·∫∑t trong $...$.
   - N·∫øu trong ƒë·∫ßu v√†o ƒë√£ c√≥ LaTeX (v√≠ d·ª• \frac{a}{b}, x^2, \sqrt{...}) th√¨ v·∫´n b·ªçc trong $...$ n·∫øu ch∆∞a c√≥.
   - Kh√¥ng d√πng \( \) ho·∫∑c \[ \] ho·∫∑c $$ $$.
4) VƒÇN B·∫¢N TH∆Ø·ªúNG kh√¥ng ƒë·∫∑t trong $...$.
5) N·∫øu ƒëo·∫°n n√†o KH√îNG CH·∫ÆC l√† to√°n hay ch·ªØ (OCR m·ªù), h√£y GI·ªÆ NGUY√äN nh∆∞ ƒë·∫ßu v√†o, kh√¥ng s·ª≠a n·ªôi dung.
6) ƒê·∫ßu ra ch·ªâ l√† VƒÇN B·∫¢N THU·∫¶N (plain text), kh√¥ng markdown, kh√¥ng ti√™u ƒë·ªÅ t·ª± ƒë·∫∑t.
""".strip()


def normalize_with_ai(api_key: str, model: str, raw_text: str, max_chars: int = 9000) -> str:
    """
    G·ªçi AI ƒë·ªÉ chu·∫©n ho√° theo lu·∫≠t $...$ + gi·ªØ xu·ªëng d√≤ng.
    Chunk theo k√Ω t·ª± ƒë·ªÉ tr√°nh v∆∞·ª£t ng·ªØ c·∫£nh.
    """
    raw_text = raw_text.replace("\r\n", "\n").replace("\r", "\n")

    chunks = []
    i = 0
    while i < len(raw_text):
        chunk = raw_text[i : i + max_chars]
        chunks.append(chunk)
        i += max_chars

    outputs = []
    for idx, ch in enumerate(chunks, start=1):
        messages = [
            {"role": "system", "content": SYSTEM_RULES},
            {"role": "user", "content": f"=== PH·∫¶N {idx}/{len(chunks)} (gi·ªØ nguy√™n xu·ªëng d√≤ng) ===\n{ch}"},
        ]
        out = sambanova_chat(
            api_key=api_key,
            model=model,
            messages=messages,
            temperature=0.1,
            max_tokens=2048,
        )
        outputs.append(out.strip("\n"))

    return "\n".join(outputs).strip("\n")


# =========================
# Build Word (.docx)
# =========================
def add_text_preserve_lines(doc: Document, text: str):
    """
    M·ªói d√≤ng th√†nh 1 paragraph ƒë·ªÉ gi·ªØ xu·ªëng d√≤ng 100%.
    D√≤ng tr·ªëng -> paragraph tr·ªëng.
    """
    text = text.replace("\r\n", "\n").replace("\r", "\n")
    for line in text.split("\n"):
        doc.add_paragraph(line)


def build_docx(
    title: str,
    final_text: str,
    images: List[Image.Image],
    embed_images: bool,
) -> bytes:
    doc = Document()
    if title.strip():
        doc.add_heading(title.strip(), level=1)

    if embed_images and images:
        doc.add_paragraph("·∫¢nh/Trang PDF (ƒë√≠nh k√®m):")
        for im in images:
            buf = io.BytesIO()
            im.save(buf, format="PNG")
            buf.seek(0)
            # ch√®n v·ª´a trang
            doc.add_picture(buf, width=Inches(6.5))

    doc.add_paragraph("N·ªôi dung tr√≠ch xu·∫•t (gi·ªØ nguy√™n xu·ªëng d√≤ng, c√¥ng th·ª©c trong $...$):")
    add_text_preserve_lines(doc, final_text)

    out = io.BytesIO()
    doc.save(out)
    return out.getvalue()


# =========================
# Streamlit UI
# =========================
st.set_page_config(page_title="·∫¢nh/PDF ‚Üí Word (SambaNova) ‚Ä¢ $...$", layout="wide")

st.title("üìÑ ·∫¢nh/PDF ‚Üí Word (.docx) b·∫±ng SambaNova (nghi√™m ng·∫∑t $...$)")

with st.sidebar:
    st.header("‚öôÔ∏è C·∫•u h√¨nh")
    api_key = st.text_input("SambaNova API Key", type="password", value=os.getenv("SAMBANOVA_API_KEY", ""))
    model = st.text_input("Model", value="Meta-Llama-3.3-70B-Instruct")
    temperature = st.slider("Temperature", 0.0, 1.0, 0.1, 0.05)
    embed_images = st.checkbox("ƒê√≠nh k√®m ·∫£nh/trang PDF v√†o Word", value=True)
    use_ai = st.checkbox("D√πng AI ƒë·ªÉ chu·∫©n ho√° c√¥ng th·ª©c v√†o $...$", value=True)
    st.caption("API SambaNova d√πng endpoint OpenAI-compatible `https://api.sambanova.ai/v1` v√† chat completions. (Xem docs)")

col1, col2 = st.columns([1, 1], gap="large")

with col1:
    st.subheader("1) D√°n ·∫£nh (Ctrl+V) ho·∫∑c t·∫£i ·∫£nh/PDF")

    st.markdown("**A. D√°n ·∫£nh**: b·∫•m n√∫t r·ªìi Ctrl+V (Chrome/Edge th∆∞·ªùng ·ªïn).")
    paste_result = paste_btn("üìã Paste image (Ctrl+V)", errors="raise")

    uploaded_images: List[Image.Image] = []
    uploaded_pdf_bytes: Optional[bytes] = None
    raw_text_sources: List[str] = []
    rendered_images: List[Image.Image] = []

    if paste_result.image_data is not None:
        # paste_result.image_data l√† PIL Image
        uploaded_images.append(paste_result.image_data)
        st.success("ƒê√£ nh·∫≠n ·∫£nh t·ª´ clipboard.")
        st.image(paste_result.image_data, caption="·∫¢nh d√°n t·ª´ clipboard", use_container_width=True)

    st.markdown("**B. T·∫£i file**:")
    up = st.file_uploader("Ch·ªçn ·∫£nh (png/jpg) ho·∫∑c PDF", type=["png", "jpg", "jpeg", "pdf"], accept_multiple_files=True)

    if up:
        for f in up:
            b = f.read()
            if f.type == "application/pdf" or f.name.lower().endswith(".pdf"):
                uploaded_pdf_bytes = b
                st.info(f"ƒê√£ nh·∫≠n PDF: {f.name}")
            else:
                img = pil_from_bytes(b)
                uploaded_images.append(img)
                st.info(f"ƒê√£ nh·∫≠n ·∫£nh: {f.name}")
                st.image(img, caption=f.name, use_container_width=True)

with col2:
    st.subheader("2) Tr√≠ch xu·∫•t & Xu·∫•t Word")

    title = st.text_input("Ti√™u ƒë·ªÅ trong Word (tu·ª≥ ch·ªçn)", value="")

    run = st.button("üöÄ Ch·∫°y chuy·ªÉn ƒë·ªïi", type="primary")

    if run:
        if not uploaded_images and not uploaded_pdf_bytes:
            st.error("Ch∆∞a c√≥ ·∫£nh ho·∫∑c PDF.")
            st.stop()

        with st.spinner("ƒêang tr√≠ch xu·∫•t n·ªôi dung..."):
            # PDF
            if uploaded_pdf_bytes:
                pdf_raw, pdf_imgs = extract_pdf_text_or_ocr(uploaded_pdf_bytes)
                raw_text_sources.append(pdf_raw)
                if embed_images:
                    rendered_images.extend(pdf_imgs)

            # ·∫¢nh
            if uploaded_images:
                for img in uploaded_images:
                    if embed_images:
                        rendered_images.append(img)
                    # OCR ƒë·ªÉ l·∫•y text (n·∫øu ·∫£nh ch·ª©a ch·ªØ)
                    try:
                        raw_text_sources.append(ocr_image_pil(img))
                    except Exception as e:
                        raw_text_sources.append("")  # v·∫´n cho xu·∫•t word, ch·ªâ c√≥ ·∫£nh
                        st.warning(str(e))

            raw_text = ("\n\n".join([t for t in raw_text_sources if t is not None])).strip()

        if not raw_text and not (embed_images and rendered_images):
            st.error("Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c text v√† c≈©ng kh√¥ng c√≥ ·∫£nh ƒë·ªÉ ƒë√≠nh k√®m.")
            st.stop()

        final_text = raw_text

        if use_ai and raw_text.strip():
            with st.spinner("ƒêang chu·∫©n ho√° b·∫±ng SambaNova (gi·ªØ xu·ªëng d√≤ng, √©p $...$)..."):
                try:
                    # override temperature theo sidebar
                    # (truy·ªÅn v√†o normalize -> sambanova_chat ƒëang d√πng 0.1; b·∫°n mu·ªën d√πng slider th√¨ thay ·ªü ƒë√¢y)
                    final_text = normalize_with_ai(api_key=api_key, model=model, raw_text=raw_text)
                except Exception as e:
                    st.error(f"L·ªói SambaNova: {e}")
                    st.stop()

        st.markdown("### Xem tr∆∞·ªõc (text)")
        st.text_area("K·∫øt qu·∫£", final_text, height=360)

        with st.spinner("ƒêang t·∫°o file Word (.docx)..."):
            docx_bytes = build_docx(
                title=title,
                final_text=final_text,
                images=rendered_images,
                embed_images=embed_images,
            )

        st.success("Xong! T·∫£i file Word ·ªü ƒë√¢y:")
        st.download_button(
            label="‚¨áÔ∏è Download .docx",
            data=docx_bytes,
            file_name="output.docx",
            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        )

st.divider()
st.caption(
    "G·ª£i √Ω: N·∫øu PDF l√† d·∫°ng scan/·∫£nh m·ªù, OCR s·∫Ω quy·∫øt ƒë·ªãnh ch·∫•t l∆∞·ª£ng. "
    "B·∫°n c√≥ th·ªÉ tƒÉng DPI trong code (extract_pdf_text_or_ocr) ƒë·ªÉ OCR r√µ h∆°n."
)
